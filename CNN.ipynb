{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNu1eeYWVJ7CqpsPbq8cokL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"-T37Ln9ZLlWv"},"outputs":[],"source":["import tensorflow as tf\n","\n","# Load dataset (for demonstration purposes, you can replace this with your own dataset)\n","mnist = tf.keras.datasets.mnist\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","x_train, x_test = x_train / 255.0, x_test / 255.0\n","\n","# Define the CNN model\n","model = tf.keras.models.Sequential([\n","    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n","    tf.keras.layers.MaxPooling2D((2, 2)),\n","    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D((2, 2)),\n","    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(64, activation='relu'),\n","    tf.keras.layers.Dense(10, activation='softmax')\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","# Reshape the input data to fit the CNN input shape\n","x_train = x_train.reshape((x_train.shape[0], 28, 28, 1))\n","x_test = x_test.reshape((x_test.shape[0], 28, 28, 1))\n","\n","# Train the model\n","model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n","\n","# Evaluate the model\n","test_loss, test_acc = model.evaluate(x_test, y_test)\n","print('Test accuracy:', test_acc)\n","\n","\n","\n","\"\"\"\n","Description:\n","    This code demonstrates the creation, training, and evaluation of a Convolutional Neural Network (CNN) model for classifying hand-written digits from the MNIST dataset.\n","    The CNN architecture consists of convolutional layers followed by max-pooling layers for downsampling and fully connected layers for classification.\n","\n","Alternatives:\n","    Other deep learning architectures such as Recurrent Neural Networks (RNNs) or Transformer models could be used depending on the nature of the data and the specific problem.\n","    Different CNN architectures such as VGG, ResNet, or Inception could be explored for better performance or specific requirements.\n","\n","Benefits:\n","    - CNNs are particularly effective for image classification tasks due to their ability to learn hierarchical features from raw pixel values.\n","    - TensorFlow provides a high-level API making it easy to build, train, and deploy deep learning models.\n","    - The code showcases a simple yet effective CNN architecture suitable for beginners and small-scale image classification tasks.\n","\n","Downsides:\n","    - CNNs may require significant computational resources, especially for large datasets and complex architectures.\n","    - The performance of the CNN heavily depends on the quality and quantity of the training data.\n","    - Tuning hyperparameters and architecture design can be time-consuming and require expertise.\n","    - Overfitting can occur, especially with limited training data or overly complex models. Regularization techniques may be needed to mitigate this.\n","\"\"\"\n","\n"]},{"cell_type":"code","source":["import tensorflow as tf\n","\n","def VGG16(input_shape, num_classes):\n","    \"\"\"\n","    Create VGG16 architecture.\n","\n","    Args:\n","    - input_shape (tuple): Input shape of images (height, width, channels).\n","    - num_classes (int): Number of classes for classification.\n","\n","    Returns:\n","    - model (tf.keras.models.Model): VGG16 model.\n","\n","    Description:\n","    VGG16 is a widely used convolutional neural network architecture proposed by Simonyan and Zisserman in their paper \"Very Deep Convolutional Networks for Large-Scale Image Recognition\".\n","    It is characterized by its simplicity and uniform architecture, consisting of multiple stacked convolutional layers followed by max-pooling layers.\n","    The VGG16 model consists of 13 convolutional layers and 3 fully connected layers, achieving impressive performance on image classification tasks.\n","\n","    Benefits:\n","    - VGG16 has a simple and uniform architecture, making it easy to understand and implement.\n","    - It achieves excellent performance on a wide range of image classification tasks, particularly when trained on large datasets.\n","    - Transfer learning: Pre-trained VGG16 models on ImageNet can be fine-tuned for specific image classification tasks, saving time and computational resources.\n","\n","    Use Cases:\n","    - Image classification: VGG16 is commonly used for tasks such as object recognition, scene classification, and fine-grained categorization.\n","    - Feature extraction: The learned representations from VGG16's convolutional layers can be used as features for other computer vision tasks such as object detection and segmentation.\n","    - Transfer learning: Pre-trained VGG16 models are often employed as a starting point for transfer learning in various domains, including medical imaging, satellite imagery analysis, and natural language processing.\n","    \"\"\"\n","    model = tf.keras.models.Sequential([\n","        tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n","        tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n","        tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2)),\n","\n","        tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n","        tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n","        tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2)),\n","\n","        tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n","        tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n","        tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n","        tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2)),\n","\n","        tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same'),\n","        tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same'),\n","        tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same'),\n","        tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2)),\n","\n","        tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same'),\n","        tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same'),\n","        tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same'),\n","        tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2)),\n","\n","        tf.keras.layers.Flatten(),\n","        tf.keras.layers.Dense(4096, activation='relu'),\n","        tf.keras.layers.Dense(4096, activation='relu'),\n","        tf.keras.layers.Dense(num_classes, activation='softmax')\n","    ])\n","\n","    return model\n","\n","# Example usage:\n","input_shape = (224, 224, 3)  # Example input shape for VGG16\n","num_classes = 1000  # Example number of classes\n","vgg16_model = VGG16(input_shape, num_classes)\n"],"metadata":{"id":"S-To0YxQMzqb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","\n","def ResNet50(input_shape, num_classes):\n","    \"\"\"\n","    Create ResNet50 architecture.\n","\n","    Args:\n","    - input_shape (tuple): Input shape of images (height, width, channels).\n","    - num_classes (int): Number of classes for classification.\n","\n","    Returns:\n","    - model (tf.keras.models.Model): ResNet50 model.\n","\n","    Description:\n","    ResNet (Residual Network) is a deep neural network architecture proposed by Kaiming He et al. in their paper \"Deep Residual Learning for Image Recognition\".\n","    It addresses the problem of vanishing gradients in very deep networks by introducing skip connections (or shortcuts) which allow gradients to flow more easily during training.\n","    ResNet50 is a specific variant of ResNet which consists of 50 layers, including convolutional layers, pooling layers, and fully connected layers.\n","\n","    Benefits:\n","    - ResNet50 can train very deep neural networks effectively without suffering from the vanishing gradient problem.\n","    - It achieves state-of-the-art performance on image classification tasks and has been widely adopted in various computer vision applications.\n","    - The skip connections in ResNet facilitate training of deeper networks and allow for better feature propagation, leading to improved performance.\n","\n","    Use Cases:\n","    - Image classification: ResNet50 is commonly used for tasks such as object recognition, scene classification, and fine-grained categorization.\n","    - Object detection: ResNet-based architectures are often used as backbone networks in object detection systems such as Faster R-CNN and YOLO.\n","    - Image segmentation: ResNet features can be used for semantic segmentation tasks to accurately classify each pixel in an image.\n","    \"\"\"\n","    model = tf.keras.applications.ResNet50(\n","        include_top=True,  # Include fully connected layers for classification\n","        weights=None,  # Random initialization of weights\n","        input_tensor=None,\n","        input_shape=input_shape,\n","        pooling=None,  # No pooling layer, we use global average pooling later\n","        classes=num_classes\n","    )\n","\n","    return model\n","\n","# Example usage:\n","input_shape = (224, 224, 3)  # Example input shape for ResNet50\n","num_classes = 1000  # Example number of classes\n","resnet50_model = ResNet50(input_shape, num_classes)\n"],"metadata":{"id":"38IXk8naM0fX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","\n","def InceptionV3(input_shape, num_classes):\n","    \"\"\"\n","    Create InceptionV3 architecture.\n","\n","    Args:\n","    - input_shape (tuple): Input shape of images (height, width, channels).\n","    - num_classes (int): Number of classes for classification.\n","\n","    Returns:\n","    - model (tf.keras.models.Model): InceptionV3 model.\n","\n","    Description:\n","    InceptionV3 is a deep convolutional neural network architecture proposed by Szegedy et al. in their paper \"Rethinking the Inception Architecture for Computer Vision\".\n","    It is characterized by its use of inception modules, which are multi-branch convolutional blocks that capture features at different scales.\n","    InceptionV3 achieves state-of-the-art performance on image classification tasks with significantly fewer parameters compared to previous architectures.\n","\n","    Benefits:\n","    - InceptionV3 effectively captures features at different scales using inception modules, leading to improved performance on image classification tasks.\n","    - It achieves good trade-off between accuracy and computational efficiency, making it suitable for deployment on resource-constrained devices.\n","    - The architecture is highly modular, allowing for easy adaptation and transfer learning to different tasks and datasets.\n","\n","    Use Cases:\n","    - Image classification: InceptionV3 is commonly used for tasks such as object recognition, scene classification, and fine-grained categorization.\n","    - Transfer learning: Pre-trained InceptionV3 models on large-scale datasets such as ImageNet can be fine-tuned for specific image classification tasks, saving time and computational resources.\n","    - Feature extraction: The learned representations from InceptionV3's convolutional layers can be used as features for other computer vision tasks such as object detection and segmentation.\n","    \"\"\"\n","    model = tf.keras.applications.InceptionV3(\n","        include_top=True,  # Include fully connected layers for classification\n","        weights=None,  # Random initialization of weights\n","        input_tensor=None,\n","        input_shape=input_shape,\n","        pooling=None,  # No pooling layer, we use global average pooling later\n","        classes=num_classes\n","    )\n","\n","    return model\n","\n","# Example usage:\n","input_shape = (299, 299, 3)  # Example input shape for InceptionV3\n","num_classes = 1000  # Example number of classes\n","inceptionv3_model = InceptionV3(input_shape, num_classes)\n"],"metadata":{"id":"y29j0mG-NMTO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"MHFZ0-qPNMtu"},"execution_count":null,"outputs":[]}]}